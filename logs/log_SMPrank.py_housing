/home/jasonzhang/anaconda2/lib/python2.7/site-packages/numpy/ma/core.py:867: RuntimeWarning: invalid value encountered in less_equal
  return umath.less_equal(x, self.critical_value)
N, d, L:  364 6 6
loss_valid 0 1.70264326715
loss_train 0 1.6326936655
loss_valid 1 1.67489978673
loss_train 1 1.60578578393
loss_valid 2 1.64847558508
loss_train 2 1.57789112951
loss_valid 3 1.62371207833
loss_train 3 1.55058355365
loss_valid 4 1.60073127601
loss_train 4 1.52477190535
loss_valid 5 1.57921671347
loss_train 5 1.50074341789
loss_valid 6 1.55918914764
loss_train 6 1.47864138596
loss_valid 7 1.54046434642
loss_train 7 1.45859939895
loss_valid 8 1.52316864608
loss_train 8 1.44061793954
loss_valid 9 1.50745521365
loss_train 9 1.42412886164
loss_valid 10 1.49312518469
loss_train 10 1.40853278917
loss_valid 11 1.47992330818
loss_train 11 1.39315188339
loss_valid 12 1.46733496741
loss_train 12 1.37755868725
loss_valid 13 1.45481498146
loss_train 13 1.36134536077
loss_valid 14 1.44146670583
loss_train 14 1.34427990723
loss_valid 15 1.4272190973
loss_train 15 1.32613322271
loss_valid 16 1.41156617878
loss_train 16 1.30692602849
loss_valid 17 1.39452035132
loss_train 17 1.28670566513
loss_valid 18 1.37619378239
loss_train 18 1.26564482396
loss_valid 19 1.35676902519
loss_train 19 1.24386075553
loss_valid 20 1.33603899685
loss_train 20 1.22135825917
loss_valid 21 1.31389585301
loss_train 21 1.19799051244
loss_valid 22 1.29040465298
loss_train 22 1.17341196441
loss_valid 23 1.26613161123
loss_train 23 1.14865100106
loss_valid 24 1.24157184613
loss_train 24 1.12452271912
loss_valid 25 1.21735328793
loss_train 25 1.1012070102
loss_valid 26 1.1935356155
loss_train 26 1.07861866906
loss_valid 27 1.17069777811
loss_train 27 1.05680646981
loss_valid 28 1.14844009542
loss_train 28 1.03633488964
loss_valid 29 1.1275226938
loss_train 29 1.0172056899
loss_valid 30 1.10794497757
loss_train 30 0.999527548202
loss_valid 31 1.08974370591
loss_train 31 0.982965457366
loss_valid 32 1.07363741791
loss_train 32 0.967455344432
loss_valid 33 1.05753293099
loss_train 33 0.952847586853
loss_valid 34 1.04340528846
loss_train 34 0.938999968376
loss_valid 35 1.03236306792
loss_train 35 0.925769885898
loss_valid 36 1.0211777356
loss_train 36 0.913371101866
loss_valid 37 1.01272804468
loss_train 37 0.901683476393
loss_valid 38 1.005140362
loss_train 38 0.890851834389
loss_valid 39 0.999221983547
loss_train 39 0.880616962501
loss_valid 40 0.990423556515
loss_train 40 0.870978295434
loss_valid 41 0.98611895087
loss_train 41 0.861667900407
loss_valid 42 0.982873917607
loss_train 42 0.852607700448
loss_valid 43 0.976974989512
loss_train 43 0.843709817902
loss_valid 44 0.972136781532
loss_train 44 0.835008733767
loss_valid 45 0.968384345305
loss_train 45 0.826574752469
loss_valid 46 0.965227005733
loss_train 46 0.818692200572
loss_valid 47 0.961231441405
loss_train 47 0.811501402579
loss_valid 48 0.95710072656
loss_train 48 0.804957598406
loss_valid 49 0.953819487398
loss_train 49 0.798894616133
loss_valid 50 0.950010438268
loss_train 50 0.793282164481
loss_valid 51 0.946738348565
loss_train 51 0.788067896871
loss_valid 52 0.943852890596
loss_train 52 0.783164601106
loss_valid 53 0.940870662121
loss_train 53 0.778608770684
loss_valid 54 0.938258140588
loss_train 54 0.774285311697
loss_valid 55 0.93631282408
loss_train 55 0.770268792131
loss_valid 56 0.934685885577
loss_train 56 0.766429708442
loss_valid 57 0.933709420312
loss_train 57 0.76277406908
loss_valid 58 0.933414329845
loss_train 58 0.759306333235
loss_valid 59 0.934832809783
loss_train 59 0.755919490004
early stop at the end of epoch:  59
[0.08823529411764706, 0, 0, 0.65686274509803921, 0.77450980392156865, 0.46078431372549017, 0.45098039215686275, 0.65686274509803921, 0.82352941176470584, 0.6568627450980392, 0.7745098039215687, 0.46078431372549017, 0.45098039215686275, 0.6568627450980392, 0.8235294117647058, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 0, 0.62070480443945675, 0.27581699346405231, nan, 0.6724137931034483, 0.6744186046511628, 0.7073170731707317, 0.5416666666666666, 0.40816326530612246, 0.7291666666666666, nan, 0.9473684210526315, 0.9152542372881356, 0.7719298245614035, 0.5208333333333334, 0.36507936507936506, 0.4897959183673469, nan, 0.7096774193548387, 0.5081967213114754, 0.2571428571428571, 0.35384615384615387, 0.425531914893617, 0.5, nan, 0.47540983606557374, 0.35135135135135137, 0.5517241379310345, 0.5306122448979592, 0.7777777777777778, 0.8666666666666667, nan, 0.3469387755102041, 0.8245614035087719, 0.7241379310344828, 0.971830985915493, 0.9710144927536232, 0.6842105263157895, nan, 0, 56, 41, 39, 46, 47, 46, 0, 55, 57, 55, 46, 61, 47, 0, 60, 59, 33, 63, 45, 42, 0, 59, 35, 56, 47, 43, 43, 0, 47, 55, 56, 69, 67, 55, 0, 0.58418969561655298]
N, d, L:  365 6 6
distinct features:  100 distinct pairlabel:  97
Traceback (most recent call last):
  File "SMPrank.py", line 366, in <module>
    results = crossValidate(x,y,K=100)
  File "SMPrank.py", line 342, in crossValidate
    y_pred = SmpRank(K=K).fit(x_train, y_train).predict(x_test)
  File "SMPrank.py", line 70, in fit
    self.initialize(N,d,L, x_train, y_train)
  File "SMPrank.py", line 229, in initialize
    raise ValueError("too many prototypes")
ValueError: too many prototypes
