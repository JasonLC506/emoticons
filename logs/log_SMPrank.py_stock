N, d, L:  684 5 5
distinct features:  100 distinct pairlabel:  49
Traceback (most recent call last):
  File "SMPrank.py", line 366, in <module>
    results = crossValidate(x,y,K=100)
  File "SMPrank.py", line 342, in crossValidate
    y_pred = SmpRank(K=K).fit(x_train, y_train).predict(x_test)
  File "SMPrank.py", line 70, in fit
    self.initialize(N,d,L, x_train, y_train)
  File "SMPrank.py", line 229, in initialize
    raise ValueError("too many prototypes")
ValueError: too many prototypes
/home/jasonzhang/anaconda2/lib/python2.7/site-packages/numpy/ma/core.py:867: RuntimeWarning: invalid value encountered in less_equal
  return umath.less_equal(x, self.critical_value)
dataset, N,d,L,K stock 950 5 5 19
N, d, L:  684 5 5
loss_valid 0 1.12004555258
loss_train 0 1.10761076042
loss_valid 1 0.957368316813
loss_train 1 0.947007385596
loss_valid 2 0.830600213212
loss_train 2 0.819515421506
loss_valid 3 0.721878423003
loss_train 3 0.709226699972
loss_valid 4 0.624833846062
loss_train 4 0.609622140056
loss_valid 5 0.544766966252
loss_train 5 0.525602074115
loss_valid 6 0.483272801084
loss_train 6 0.459046757076
loss_valid 7 0.437963943828
loss_train 7 0.408538712822
loss_valid 8 0.404414716453
loss_train 8 0.370616271266
loss_valid 9 0.378555774668
loss_train 9 0.341541119654
loss_valid 10 0.357471252712
loss_train 10 0.318773775174
loss_valid 11 0.339507186871
loss_train 11 0.300541998674
loss_valid 12 0.323744032231
loss_train 12 0.285659437251
loss_valid 13 0.309712537646
loss_train 13 0.273453018616
loss_valid 14 0.297187319325
loss_train 14 0.263340626287
loss_valid 15 0.286324707992
loss_train 15 0.254883844761
loss_valid 16 0.276974273189
loss_train 16 0.247799167447
loss_valid 17 0.269114170139
loss_train 17 0.241800381014
loss_valid 18 0.262250608203
loss_train 18 0.2369438846
loss_valid 19 0.256266549179
loss_train 19 0.232966595844
loss_valid 20 0.250992290823
loss_train 20 0.229696944156
loss_valid 21 0.246141596179
loss_train 21 0.226895813169
loss_valid 22 0.241685738144
loss_train 22 0.224420087266
loss_valid 23 0.238163390641
loss_train 23 0.222181304251
loss_valid 24 0.235720680343
loss_train 24 0.220157912856
loss_valid 25 0.233971534476
loss_train 25 0.218396201738
loss_valid 26 0.232666774425
loss_train 26 0.216879190688
loss_valid 27 0.231633055476
loss_train 27 0.215522052215
loss_valid 28 0.230707112041
loss_train 28 0.21426290396
loss_valid 29 0.229775493847
loss_train 29 0.213147787844
loss_valid 30 0.228995545319
loss_train 30 0.212213413662
loss_valid 31 0.22821716231
loss_train 31 0.21141839664
loss_valid 32 0.227563702153
loss_train 32 0.210712446299
loss_valid 33 0.226952428828
loss_train 33 0.210086052807
loss_valid 34 0.226373848017
loss_train 34 0.209517098144
loss_valid 35 0.225818312413
loss_train 35 0.208996992972
loss_valid 36 0.225363744106
loss_train 36 0.208524007809
loss_valid 37 0.224914779451
loss_train 37 0.208091490374
loss_valid 38 0.224521471469
loss_train 38 0.207685419411
loss_valid 39 0.224091977955
loss_train 39 0.207316268183
loss_valid 40 0.223663675506
loss_train 40 0.206968061991
loss_valid 41 0.22329061097
loss_train 41 0.206632869228
loss_valid 42 0.222858153734
loss_train 42 0.206330383003
loss_valid 43 0.222501507341
loss_train 43 0.206040138431
loss_valid 44 0.222120837645
loss_train 44 0.205748291866
loss_valid 45 0.221702782563
loss_train 45 0.205483074166
loss_valid 46 0.221306037952
loss_train 46 0.205195729764
loss_valid 47 0.220919804986
loss_train 47 0.20492880918
loss_valid 48 0.220646483741
loss_train 48 0.204678282233
loss_valid 49 0.220662537533
loss_train 49 0.204402522338
early stop at the end of epoch:  49
[0.5157894736842106, 0, 0, 0.84736842105263155, 0.80526315789473679, 0.88947368421052631, 0.91578947368421049, 0.84736842105263155, 0.8473684210526315, 0.8052631578947368, 0.8894736842105263, 0.9157894736842105, 0.8473684210526315, 190.0, 190.0, 190.0, 190.0, 190.0, 0, 0.86020552213339385, 0.83578947368421042, nan, 0.7530864197530864, 0.9318181818181818, 0.875968992248062, 0.968421052631579, 0.9911504424778761, nan, 0.8818897637795275, 0.7676767676767676, 0.9357798165137615, 0.9905660377358491, 0.9104477611940298, nan, 0.9367088607594937, 0.8061224489795918, 0.8153846153846154, 0.9789473684210527, 0.991304347826087, nan, 0.925, 0.9191919191919192, 0.8470588235294118, 0.9479166666666666, 0.9385964912280702, nan, 0, 79, 86, 127, 93, 111, 0, 125, 97, 107, 104, 65, 0, 77, 96, 63, 93, 113, 0, 78, 97, 83, 94, 112, 0, 0.9026947640586177]
N, d, L:  684 5 5
loss_valid 0 1.01693875474
loss_train 0 0.956271946797
loss_valid 1 0.867103972369
loss_train 1 0.802136307666
loss_valid 2 0.753504553708
loss_train 2 0.688458839493
loss_valid 3 0.655942681805
loss_train 3 0.596481853931
loss_valid 4 0.565355539159
loss_train 4 0.517190954319
loss_valid 5 0.484466013286
loss_train 5 0.45001970862
loss_valid 6 0.420166542332
loss_train 6 0.397121067576
loss_valid 7 0.373464522373
loss_train 7 0.357743943358
loss_valid 8 0.34079282059
loss_train 8 0.328731083742
loss_valid 9 0.317685552909
loss_train 9 0.306743018816
loss_valid 10 0.300913945603
loss_train 10 0.289600378722
loss_valid 11 0.288074523919
loss_train 11 0.276065078857
loss_valid 12 0.277927381609
loss_train 12 0.265155951325
loss_valid 13 0.269381692861
loss_train 13 0.255969198276
loss_valid 14 0.261906158448
loss_train 14 0.247817342715
loss_valid 15 0.255127887418
loss_train 15 0.240437464515
loss_valid 16 0.24910728443
loss_train 16 0.233906846914
loss_valid 17 0.244000448139
loss_train 17 0.228336131128
loss_valid 18 0.239703439747
loss_train 18 0.223724008889
loss_valid 19 0.236109038185
loss_train 19 0.219926413799
loss_valid 20 0.233136988114
loss_train 20 0.216784020628
loss_valid 21 0.230572724641
loss_train 21 0.214143920913
loss_valid 22 0.228352408783
loss_train 22 0.211905124194
loss_valid 23 0.226386982401
loss_train 23 0.209975371627
loss_valid 24 0.224622414836
loss_train 24 0.208251624514
loss_valid 25 0.223013492233
loss_train 25 0.206731363215
loss_valid 26 0.221569147424
loss_train 26 0.205352113364
loss_valid 27 0.220349986802
loss_train 27 0.204125746605
loss_valid 28 0.219392966957
loss_train 28 0.20299228649
loss_valid 29 0.218779322531
loss_train 29 0.201944684223
loss_valid 30 0.21820052214
loss_train 30 0.201007903511
loss_valid 31 0.218074275583
loss_train 31 0.200099785033
loss_valid 32 0.21788166175
loss_train 32 0.199236428004
loss_valid 33 0.217545937425
loss_train 33 0.198334034588
loss_valid 34 0.2175086527
loss_train 34 0.197303130727
loss_valid 35 0.217281121486
loss_train 35 0.196293665865
loss_valid 36 0.217032302777
loss_train 36 0.195588288482
loss_valid 37 0.216832316062
loss_train 37 0.194992820971
loss_valid 38 0.216638211554
loss_train 38 0.194472825264
loss_valid 39 0.216467216713
loss_train 39 0.194006362006
loss_valid 40 0.216273726022
loss_train 40 0.193562687305
loss_valid 41 0.216087257041
loss_train 41 0.193160826096
loss_valid 42 0.215912788336
loss_train 42 0.192796313256
loss_valid 43 0.2158209441
loss_train 43 0.192466480165
loss_valid 44 0.215675100731
loss_train 44 0.192153496677
loss_valid 45 0.21563315854
loss_train 45 0.191884276357
loss_valid 46 0.215575099074
loss_train 46 0.191609242798
loss_valid 47 0.215527972
loss_train 47 0.191356684435
loss_valid 48 0.215490899158
loss_train 48 0.191163557453
loss_valid 49 0.215452233866
loss_train 49 0.190903316242
loss_valid 50 0.21540720071
loss_train 50 0.190714238808
loss_valid 51 0.215413430106
loss_train 51 0.190505847373
early stop at the end of epoch:  51
[0.5894736842105263, 0, 0, 0.95789473684210524, 0.83684210526315794, 0.90000000000000002, 0.85263157894736841, 0.84210526315789469, 0.9578947368421052, 0.8368421052631579, 0.9, 0.8526315789473684, 0.8421052631578947, 190.0, 190.0, 190.0, 190.0, 190.0, 0, 0.87673091954519478, 0.86842105263157898, nan, 0.9662921348314607, 0.9325842696629213, 0.9910714285714286, 0.9813084112149533, 0.9047619047619048, nan, 0.937007874015748, 0.8214285714285714, 0.9401709401709402, 0.9904761904761905, 0.7761194029850746, nan, 0.9411764705882353, 0.9431818181818182, 0.6951219512195121, 0.9818181818181818, 0.9761904761904762, nan, 0.956989247311828, 0.9540229885057471, 0.8441558441558441, 0.9528301886792453, 0.8712871287128713, nan, 0, 87, 87, 110, 105, 103, 0, 125, 82, 115, 103, 65, 0, 66, 86, 80, 108, 124, 0, 91, 85, 75, 104, 99, 0, 0.91437556341182924]
N, d, L:  684 5 5
loss_valid 0 1.18779402664
loss_train 0 1.13415545182
loss_valid 1 1.01043117387
loss_train 1 0.950600598456
loss_valid 2 0.86937618082
loss_train 2 0.803886753273
loss_valid 3 0.749155655091
loss_train 3 0.677214131559
loss_valid 4 0.645319768862
loss_train 4 0.567692793562
loss_valid 5 0.559125103169
loss_train 5 0.477971729212
loss_valid 6 0.490812234994
loss_train 6 0.409215289871
loss_valid 7 0.438644522143
loss_train 7 0.358913944546
loss_valid 8 0.400006806273
loss_train 8 0.323435957491
loss_valid 9 0.371512392529
loss_train 9 0.298680063019
loss_valid 10 0.35005040525
loss_train 10 0.281087777527
loss_valid 11 0.33334959234
loss_train 11 0.26807670796
loss_valid 12 0.320117270133
loss_train 12 0.258170041512
loss_valid 13 0.309338699731
loss_train 13 0.250453198836
loss_valid 14 0.300747906217
loss_train 14 0.244365884353
loss_valid 15 0.293797828482
loss_train 15 0.239552771018
loss_valid 16 0.288272026336
loss_train 16 0.235789773414
loss_valid 17 0.283815323507
loss_train 17 0.232792210479
loss_valid 18 0.280290084193
loss_train 18 0.230344227461
loss_valid 19 0.277505143406
loss_train 19 0.228273785219
loss_valid 20 0.275089904344
loss_train 20 0.226457120924
loss_valid 21 0.273375974069
loss_train 21 0.224840593992
loss_valid 22 0.271922609466
loss_train 22 0.223409421284
loss_valid 23 0.270589817829
loss_train 23 0.22211395554
loss_valid 24 0.269462490734
loss_train 24 0.2209838863
loss_valid 25 0.268503682665
loss_train 25 0.220026778352
loss_valid 26 0.267539560398
loss_train 26 0.219210155508
loss_valid 27 0.266634251468
loss_train 27 0.218493543777
loss_valid 28 0.265650174257
loss_train 28 0.217861270441
loss_valid 29 0.264809407859
loss_train 29 0.217271899509
loss_valid 30 0.263820112464
loss_train 30 0.216673322269
loss_valid 31 0.26291002035
loss_train 31 0.216008923545
loss_valid 32 0.261799946329
loss_train 32 0.21526455145
loss_valid 33 0.260949751541
loss_train 33 0.214610687422
loss_valid 34 0.25995485549
loss_train 34 0.214070762423
loss_valid 35 0.258966985583
loss_train 35 0.213568609502
loss_valid 36 0.257617180228
loss_train 36 0.213078834458
loss_valid 37 0.256243211969
loss_train 37 0.212547977389
loss_valid 38 0.254738812498
loss_train 38 0.211969694757
loss_valid 39 0.253541684963
loss_train 39 0.211321687665
loss_valid 40 0.252449786686
loss_train 40 0.21074921316
loss_valid 41 0.251529993362
loss_train 41 0.210221954781
loss_valid 42 0.250915952633
loss_train 42 0.209628177189
loss_valid 43 0.250189745825
loss_train 43 0.209096014208
loss_valid 44 0.24956436914
loss_train 44 0.208520138937
loss_valid 45 0.249026783398
loss_train 45 0.208002146267
loss_valid 46 0.248531751678
loss_train 46 0.207481375044
loss_valid 47 0.248001791583
loss_train 47 0.206970123429
loss_valid 48 0.247532821012
loss_train 48 0.206439686997
loss_valid 49 0.246932885022
loss_train 49 0.20596541826
loss_valid 50 0.246503230082
loss_train 50 0.205486601836
loss_valid 51 0.24607313079
loss_train 51 0.205028273278
loss_valid 52 0.245590175502
loss_train 52 0.204582836771
loss_valid 53 0.245105161363
loss_train 53 0.204134463842
loss_valid 54 0.244659941088
loss_train 54 0.203751761769
loss_valid 55 0.244216117609
loss_train 55 0.203406256704
loss_valid 56 0.243795644755
loss_train 56 0.203105032142
loss_valid 57 0.243433145293
loss_train 57 0.202812743438
loss_valid 58 0.243064284411
loss_train 58 0.202551894597
loss_valid 59 0.242730583557
loss_train 59 0.202299368714
loss_valid 60 0.242382146547
loss_train 60 0.20205660566
loss_valid 61 0.242036290497
loss_train 61 0.201824065198
loss_valid 62 0.241710179926
loss_train 62 0.20160643316
loss_valid 63 0.241399812897
loss_train 63 0.201398896792
loss_valid 64 0.241103568702
loss_train 64 0.201199868942
loss_valid 65 0.240807178157
loss_train 65 0.201008373606
loss_valid 66 0.240504622697
loss_train 66 0.20082476648
loss_valid 67 0.240227306136
loss_train 67 0.200655578667
loss_valid 68 0.239944658678
loss_train 68 0.200484839227
loss_valid 69 0.239679939887
loss_train 69 0.200339075901
loss_valid 70 0.239415736462
loss_train 70 0.200167822529
loss_valid 71 0.239165180984
loss_train 71 0.200041484755
loss_valid 72 0.238919470736
loss_train 72 0.199871968261
loss_valid 73 0.238673797489
loss_train 73 0.19972728587
loss_valid 74 0.238433239952
loss_train 74 0.199592188913
loss_valid 75 0.238209712377
loss_train 75 0.199499498403
loss_valid 76 0.237989794366
loss_train 76 0.199427689288
loss_valid 77 0.237770117547
loss_train 77 0.199240602061
loss_valid 78 0.237555440128
loss_train 78 0.199097918239
loss_valid 79 0.237359178539
loss_train 79 0.199SMPrank.py:89: UserWarning: training set loss increase
  warnings.warn("training set loss increase")
053025038
loss_valid 80 0.237158932214
loss_train 80 0.198994839832
loss_valid 81 0.236957498216
loss_train 81 0.198803378267
loss_valid 82 0.236763722054
loss_train 82 0.198676703171
loss_valid 83 0.236585121287
loss_train 83 0.198690588661
last epoch loss:  0.198676703171
current epoch loss:  0.198690588661
loss_valid 84 0.236396074371
loss_train 84 0.198487216144
loss_valid 85 0.23621184527
loss_train 85 0.198413653709
loss_valid 86 0.236032585028
loss_train 86 0.198298875923
loss_valid 87 0.235866166888
loss_train 87 0.198367757613
last epoch loss:  0.198298875923
current epoch loss:  0.198367757613
loss_valid 88 0.235690077572
loss_train 88 0.198204840175
loss_valid 89 0.235522637093
loss_train 89 0.198191289659
loss_valid 90 0.235356312501
loss_train 90 0.19802156153
loss_valid 91 0.235195056814
loss_train 91 0.198058411083
last epoch loss:  0.19802156153
current epoch loss:  0.198058411083
loss_valid 92 0.235031678977
loss_train 92 0.197881480616
loss_valid 93 0.234876204668
loss_train 93 0.197770870196
loss_valid 94 0.234722134203
loss_train 94 0.197649215492
loss_valid 95 0.234571599061
loss_train 95 0.19767853205
last epoch loss:  0.197649215492
current epoch loss:  0.19767853205
loss_valid 96 0.234422231336
loss_train 96 0.197557322082
loss_valid 97 0.234276461977
loss_train 97 0.197531722885
loss_valid 98 0.234131607691
loss_train 98 0.197389794488
loss_valid 99 0.233993930178
loss_train 99 0.197383011194
[0.39473684210526316, 0, 0, 0.9263157894736842, 0.80000000000000004, 0.75263157894736843, 0.74210526315789471, 0.65789473684210531, 0.9263157894736842, 0.8, 0.7526315789473684, 0.7421052631578947, 0.6578947368421053, 190.0, 190.0, 190.0, 190.0, 190.0, 0, 0.7709224320681477, 0.54526315789473678, nan, 0.8902439024390244, 0.9555555555555556, 0.9523809523809523, 0.9777777777777777, 0.5446428571428571, nan, 0.9913793103448276, 0.8478260869565217, 0.8703703703703703, 0.5288461538461539, 0.46153846153846156, nan, 0.9701492537313433, 0.9156626506024096, 0.5730337078651685, 0.7647058823529411, 0.8267716535433071, nan, 0.9090909090909091, 0.5961538461538461, 0.627906976744186, 0.6846846846846847, 0.5188679245283019, nan, 0, 80, 88, 103, 88, 110, 0, 114, 90, 106, 102, 76, 0, 65, 81, 87, 100, 125, 0, 86, 102, 84, 109, 104, 0, 0.74789031991257049]
N, d, L:  684 5 5
loss_valid 0 1.26465824812
loss_train 0 1.25867616924
loss_valid 1 1.0359943495
loss_train 1 1.02395475033
loss_valid 2 0.838500097221
loss_train 2 0.822314669723
loss_valid 3 0.687078885193
loss_train 3 0.666698494978
loss_valid 4 0.578850669681
loss_train 4 0.555414807049
loss_valid 5 0.501403547298
loss_train 5 0.47711808805
loss_valid 6 0.443650315529
loss_train 6 0.420747518626
loss_valid 7 0.399141607613
loss_train 7 0.379103653281
loss_valid 8 0.364435352923
loss_train 8 0.347482202115
loss_valid 9 0.337121303282
loss_train 9 0.32297562096
loss_valid 10 0.315674140194
loss_train 10 0.303799965072
loss_valid 11 0.298816878541
loss_train 11 0.288528253079
loss_valid 12 0.285216865339
loss_train 12 0.276149947183
loss_valid 13 0.274106077676
loss_train 13 0.265928533757
loss_valid 14 0.265150553656
loss_train 14 0.257375448704
loss_valid 15 0.257748034789
loss_train 15 0.25013490956
loss_valid 16 0.251662125488
loss_train 16 0.243934350994
loss_valid 17 0.246575377074
loss_train 17 0.238586762635
loss_valid 18 0.242235467904
loss_train 18 0.23396419861
loss_valid 19 0.238514166766
loss_train 19 0.230022900364
loss_valid 20 0.235219055783
loss_train 20 0.226634806157
loss_valid 21 0.232275750627
loss_train 21 0.223726672725
loss_valid 22 0.229728777186
loss_train 22 0.221223186967
loss_valid 23 0.227429469876
loss_train 23 0.219025475059
loss_valid 24 0.225311039801
loss_train 24 0.217089519332
loss_valid 25 0.223289142793
loss_train 25 0.215384221283
loss_valid 26 0.221476758577
loss_train 26 0.213866499525
loss_valid 27 0.219844285749
loss_train 27 0.212512734294
loss_valid 28 0.21835451362
loss_train 28 0.211301882497
loss_valid 29 0.217011132197
loss_train 29 0.210214123781
loss_valid 30 0.215836535212
loss_train 30 0.209242813887
loss_valid 31 0.214739871435
loss_train 31 0.208366095307
loss_valid 32 0.213766855296
loss_train 32 0.207581466345
loss_valid 33 0.212946667198
loss_train 33 0.206873673114
loss_valid 34 0.212166787833
loss_train 34 0.206229482438
loss_valid 35 0.211490781796
loss_train 35 0.205643971766
loss_valid 36 0.210885314888
loss_train 36 0.205110046184
loss_valid 37 0.210355661818
loss_train 37 0.20461717639
loss_valid 38 0.209876324312
loss_train 38 0.204158684748
loss_valid 39 0.209425116876
loss_train 39 0.20373598001
loss_valid 40 0.209035694655
loss_train 40 0.20333533531
loss_valid 41 0.208647425155
loss_train 41 0.202964328132
loss_valid 42 0.208319926164
loss_train 42 0.20260567768
loss_valid 43 0.208000255266
loss_train 43 0.202268207034
loss_valid 44 0.207691676417
loss_train 44 0.201932177304
loss_valid 45 0.207389988916
loss_train 45 0.201602672778
loss_valid 46 0.207114781378
loss_train 46 0.201284799816
loss_valid 47 0.206851837931
loss_train 47 0.200986992425
loss_valid 48 0.206578243625
loss_train 48 0.200729066542
loss_valid 49 0.206324001601
loss_train 49 0.200469946927
loss_valid 50 0.206071549125
loss_train 50 0.200227853223
loss_valid 51 0.205827565823
loss_train 51 0.19999784975
loss_valid 52 0.205606976162
loss_train 52 0.199784362555
loss_valid 53 0.20541345967
loss_train 53 0.199579850649
loss_valid 54 0.205234218219
loss_train 54 0.199385407911
loss_valid 55 0.20508168704
loss_train 55 0.199193773877
loss_valid 56 0.204941218728
loss_train 56 0.199013870135
loss_valid 57 0.204813417662
loss_train 57 0.198822683378
loss_valid 58 0.204694164318
loss_train 58 0.198659968723
loss_valid 59 0.204577117821
loss_train 59 0.198483519344
loss_valid 60 0.204468965868
loss_train 60 0.198304350667
loss_valid 61 0.204362331908
loss_train 61 0.198133811012
loss_valid 62 0.204258454929
loss_train 62 0.197993374284
loss_valid 63 0.204160928842
loss_train 63 0.197866845446
loss_valid 64 0.204063397721
loss_train 64 0.197741053685
loss_valid 65 0.203973351735
loss_train 65 0.19762340349
loss_valid 66 0.203886866621
loss_train 66 0.197463005635
loss_valid 67 0.203804344106
loss_train 67 0.197219592294
loss_valid 68 0.203728451372
loss_train 68 0.196566369058
loss_valid 69 0.203668425232
loss_train 69 0.195823209376
loss_valid 70 0.203621887538
loss_train 70 0.195475547594
loss_valid 71 0.203593427761
loss_train 71 0.19531069591
loss_valid 72 0.203562854053
loss_train 72 0.195157366923
loss_valid 73 0.203529742571
loss_train 73 0.195018768839
loss_valid 74 0.203491676179
loss_train 74 0.194902138664
loss_valid 75 0.203452484372
loss_train 75 0.194831460692
loss_valid 76 0.203413043672
loss_train 76 0.194752885009
loss_valid 77 0.203372369967
loss_train 77 0.194646955626
loss_valid 78 0.203333258334
loss_train 78 0.194559330463
loss_valid 79 0.203293439998
loss_train 79 0.194489908556
loss_valid 80 0.203255543327
loss_train 80 0.1944322477
loss_valid 81 0.203218403091
loss_train 81 0.194336124566
loss_valid 82 0.203182717204
loss_train 82 0.194273767718
loss_valid 83 0.203145210908
loss_train 83 0.194237420345
loss_valid 84 0.203113009282
loss_train 84 0.194153142822
loss_valid 85 0.203080740462
loss_train 85 0.194100786785
loss_valid 86 0.203048645527
loss_train 86 0.194087399371
loss_valid 87 0.203017754378
loss_train 87 0.194015142004
loss_valid 88 0.202988998069
loss_train 88 0.193968118557
loss_valid 89 0.202960940795
loss_train 89 0.193915750119
loss_valid 90 0.202931157724
loss_train 90 0.193847829743
loss_valid 91 0.202904728621
loss_train 91 0.193825999116
loss_valid 92 0.202879815361
loss_train 92 0.193763668292
loss_valid 93 0.20285457102
loss_train 93 0.193736117369
loss_valid 94 0.202829270788
loss_train 94 0.193681174956
loss_valid 95 0.202804001929
loss_train 95 0.193642902498
loss_valid 96 0.202780907235
loss_train 96 0.193614525455
loss_valid 97 0.202758768941
loss_train 97 0.193571690251
loss_valid 98 0.202736391243
loss_train 98 0.193543401917
loss_valid 99 0.202714168855
loss_train 99 0.193509743325
[0.5210526315789473, 0, 0, 0.85263157894736841, 0.84210526315789469, 0.84736842105263155, 0.82105263157894737, 0.74210526315789471, 0.8526315789473684, 0.8421052631578947, 0.8473684210526315, 0.8210526315789474, 0.7421052631578947, 190.0, 190.0, 190.0, 190.0, 190.0, 0, 0.81998765841967858, 0.70526315789473681, nan, 0.7241379310344828, 0.9473684210526315, 0.9761904761904762, 0.9680851063829787, 0.7757009345794392, nan, 0.9821428571428571, 0.8631578947368421, 0.8928571428571429, 0.788135593220339, 0.6707317073170732, nan, 0.9743589743589743, 0.956989247311828, 0.6911764705882353, 0.7373737373737373, 0.8706896551724138, nan, 0.9523809523809523, 0.81, 0.7439024390243902, 0.7623762376237624, 0.7545454545454545, nan, 0, 85, 74, 124, 92, 105, 0, 110, 93, 110, 116, 80, 0, 76, 91, 66, 97, 114, 0, 82, 98, 80, 99, 108, 0, 0.83551757471059429]
N, d, L:  684 5 5
loss_valid 0 0.969481427099
loss_train 0 0.994016292562
loss_valid 1 0.803111552558
loss_train 1 0.828516797276
loss_valid 2 0.686410278626
loss_train 2 0.71348538041
loss_valid 3 0.597862335106
loss_train 3 0.626665787382
loss_valid 4 0.525086327495
loss_train 4 0.554628641572
loss_valid 5 0.462803373085
loss_train 5 0.491794170639
loss_valid 6 0.410662076571
loss_train 6 0.437403308327
loss_valid 7 0.368962433048
loss_train 7 0.392819189201
loss_valid 8 0.336912959357
loss_train 8 0.357774809185
loss_valid 9 0.312669672624
loss_train 9 0.330632215835
loss_valid 10 0.293910608023
loss_train 10 0.309353282778
loss_valid 11 0.278919316082
loss_train 11 0.292031320947
loss_valid 12 0.266375150609
loss_train 12 0.277540910953
loss_valid 13 0.254761644706
loss_train 13 0.265344680209
loss_valid 14 0.243070208709
loss_train 14 0.255150048116
loss_valid 15 0.229483353946
loss_train 15 0.245392114882
loss_valid 16 0.220248311437
loss_train 16 0.237783728168
loss_valid 17 0.214335143874
loss_train 17 0.231917044979
loss_valid 18 0.209983507125
loss_train 18 0.227197815806
loss_valid 19 0.206544110348
loss_train 19 0.223403371808
loss_valid 20 0.203624449613
loss_train 20 0.220216400365
loss_valid 21 0.201151433721
loss_train 21 0.217420654493
loss_valid 22 0.199055701849
loss_train 22 0.214667455787
loss_valid 23 0.197242512707
loss_train 23 0.212122930411
loss_valid 24 0.195564360874
loss_train 24 0.210234701456
loss_valid 25 0.194086015247
loss_train 25 0.208584519878
loss_valid 26 0.192693699457
loss_train 26 0.207123703378
loss_valid 27 0.191424107679
loss_train 27 0.205823109819
loss_valid 28 0.19029370413
loss_train 28 0.204637101466
loss_valid 29 0.189263969358
loss_train 29 0.203606866241
loss_valid 30 0.188352505509
loss_train 30 0.202676023765
loss_valid 31 0.187511676793
loss_train 31 0.20184418513
loss_valid 32 0.186760120248
loss_train 32 0.201097330098
loss_valid 33 0.186112319765
loss_train 33 0.200417488332
loss_valid 34 0.18551219796
loss_train 34 0.199797475193
loss_valid 35 0.184977167014
loss_train 35 0.199243805021
loss_valid 36 0.184532073511
loss_train 36 0.198732009627
loss_valid 37 0.184146139399
loss_train 37 0.198266248151
loss_valid 38 0.183827042098
loss_train 38 0.197846431004
loss_valid 39 0.183534469038
loss_train 39 0.19746056396
loss_valid 40 0.183313376351
loss_train 40 0.197104579591
loss_valid 41 0.18313963616
loss_train 41 0.1967692208
loss_valid 42 0.182960957416
loss_train 42 0.196456248634
loss_valid 43 0.182804673738
loss_train 43 0.196161741314
loss_valid 44 0.182655685047
loss_train 44 0.195886901345
loss_valid 45 0.182525067497
loss_train 45 0.195623197672
loss_valid 46 0.18238834791
loss_train 46 0.195404345939
loss_valid 47 0.182258206752
loss_train 47 0.195152195703
loss_valid 48 0.182146309605
loss_train 48 0.194922403507
loss_valid 49 0.182039850514
loss_train 49 0.194720962414
loss_valid 50 0.181938706503
loss_train 50 0.194517751602
loss_valid 51 0.181849133583
loss_train 51 0.194313150249
loss_valid 52 0.181754044083
loss_train 52 0.194119850485
loss_valid 53 0.181682431205
loss_train 53 0.193957351935
loss_valid 54 0.181603759848
loss_train 54 0.19366504213
loss_valid 55 0.181537033261
loss_train 55 0.193479132209
loss_valid 56 0.181463237929
loss_train 56 0.193295902426
loss_valid 57 0.181394665546
loss_train 57 0.193200430986
loss_valid 58 0.181330965356/home/jasonzhang/anaconda2/lib/python2.7/site-packages/numpy/lib/nanfunctions.py:703: RuntimeWarning: Mean of empty slice
  warnings.warn("Mean of empty slice", RuntimeWarning)
/home/jasonzhang/anaconda2/lib/python2.7/site-packages/numpy/lib/nanfunctions.py:1202: RuntimeWarning: Degrees of freedom <= 0 for slice.
  warnings.warn("Degrees of freedom <= 0 for slice.", RuntimeWarning)

loss_train 58 0.192946080317
loss_valid 59 0.18127496401
loss_train 59 0.19288725548
loss_valid 60 0.18122396439
loss_train 60 0.192668747118
loss_valid 61 0.18117694314
loss_train 61 0.19265642473
loss_valid 62 0.181131233977
loss_train 62 0.192555136652
loss_valid 63 0.181077701351
loss_train 63 0.1923124701
loss_valid 64 0.181028429375
loss_train 64 0.192263084499
loss_valid 65 0.180985146346
loss_train 65 0.192149117568
loss_valid 66 0.180944610964
loss_train 66 0.192145987358
loss_valid 67 0.180906636069
loss_train 67 0.192015158787
loss_valid 68 0.180863416293
loss_train 68 0.191987442745
loss_valid 69 0.18082958725
loss_train 69 0.191813918467
loss_valid 70 0.180789119136
loss_train 70 0.191732978246
loss_valid 71 0.180757558679
loss_train 71 0.191694942179
loss_valid 72 0.180727201851
loss_train 72 0.191523281862
loss_valid 73 0.18069913077
loss_train 73 0.191461135121
loss_valid 74 0.180666547991
loss_train 74 0.191454315476
loss_valid 75 0.180640915921
loss_train 75 0.191316481678
loss_valid 76 0.180615673225
loss_train 76 0.191200370365
loss_valid 77 0.180589105974
loss_train 77 0.19111696025
loss_valid 78 0.180564632151
loss_train 78 0.191079208276
loss_valid 79 0.180542491569
loss_train 79 0.190970642604
loss_valid 80 0.18052045841
loss_train 80 0.190919973307
loss_valid 81 0.180497454706
loss_train 81 0.190910976763
loss_valid 82 0.180478302728
loss_train 82 0.190862718422
loss_valid 83 0.180456713046
loss_train 83 0.190762576855
loss_valid 84 0.180437154986
loss_train 84 0.190749843141
loss_valid 85 0.180417635682
loss_train 85 0.190674673407
loss_valid 86 0.180399004496
loss_train 86 0.190637886692
loss_valid 87 0.180380801869
loss_train 87 0.190602726065
loss_valid 88 0.180364836771
loss_train 88 0.190560440352
loss_valid 89 0.180348548902
loss_train 89 0.190570509524
last epoch loss:  0.190560440352
current epoch loss:  0.190570509524
loss_valid 90 0.180333682634
loss_train 90 0.190479167906
loss_valid 91 0.180317559283
loss_train 91 0.190496323343
last epoch loss:  0.190479167906
current epoch loss:  0.190496323343
loss_valid 92 0.180304271119
loss_train 92 0.19041715931
loss_valid 93 0.180291150138
loss_train 93 0.190420398655
last epoch loss:  0.19041715931
current epoch loss:  0.190420398655
loss_valid 94 0.180276615832
loss_train 94 0.190378007544
loss_valid 95 0.180262193166
loss_train 95 0.190342621667
loss_valid 96 0.180249867451
loss_train 96 0.190316836519
loss_valid 97 0.180237337996
loss_train 97 0.190286850768
loss_valid 98 0.180225693685
loss_train 98 0.190257213855
loss_valid 99 0.180212748919
loss_train 99 0.190229808172
[0.4, 0, 0, 0.94736842105263153, 0.86315789473684212, 0.66842105263157892, 0.82105263157894737, 0.62631578947368416, 0.9473684210526315, 0.8631578947368421, 0.6684210526315789, 0.8210526315789474, 0.6263157894736842, 190.0, 190.0, 190.0, 190.0, 190.0, 0, 0.77582670731464698, 0.53157894736842104, nan, 0.9456521739130435, 0.9565217391304348, 0.9689922480620154, 0.99, 0.4803921568627451, nan, 0.9732142857142857, 0.8111111111111111, 0.9137931034482759, 0.49019607843137253, 0.23170731707317074, nan, 0.9701492537313433, 0.9247311827956989, 0.49230769230769234, 0.7596153846153846, 0.9212598425196851, nan, 0.946236559139785, 0.4787234042553192, 0.5, 0.7623762376237624, 0.4158415841584158, nan, 0, 90, 90, 127, 98, 100, 0, 110, 88, 114, 100, 80, 0, 65, 91, 63, 102, 125, 0, 91, 92, 76, 99, 99, 0, 0.69820364108304023]
{'perf': [array([   0.48421053,    0.        ,    0.        ,    0.90631579,
          0.82947368,    0.81157895,    0.83052632,    0.74315789,
          0.90631579,    0.82947368,    0.81157895,    0.83052632,
          0.74315789,  190.        ,  190.        ,  190.        ,
        190.        ,  190.        ,    0.        ,    0.82073465,
          0.69726316,           nan,    0.85588251,    0.94476963,
          0.95292082,    0.97711847,    0.73932966,           nan,
          0.95312682,    0.82224009,    0.91059427,    0.75764401,
          0.61010893,           nan,    0.95850856,    0.90933747,
          0.65340489,    0.84449211,    0.9172432 ,           nan,
          0.93793953,    0.75161843,    0.71260482,    0.8220368 ,
          0.69982772,           nan,    0.        ,   84.2       ,
         85.        ,  118.2       ,   95.2       ,  105.8       ,
          0.        ,  116.8       ,   90.        ,  110.4       ,
        105.        ,   73.2       ,    0.        ,   69.8       ,
         89.        ,   71.8       ,  100.        ,  120.2       ,
          0.        ,   85.6       ,   94.8       ,   79.6       ,
        101.        ,  104.4       ,    0.        ,    0.81973637]), array([  7.55405268e-02,   0.00000000e+00,   0.00000000e+00,
         4.71221669e-02,   2.36783619e-02,   8.84711637e-02,
         5.61359647e-02,   9.11848751e-02,   4.71221669e-02,
         2.36783619e-02,   8.84711637e-02,   5.61359647e-02,
         9.11848751e-02,   0.00000000e+00,   0.00000000e+00,
         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,
         0.00000000e+00,   4.28767310e-02,   1.40786237e-01,
                    nan,   9.93511483e-02,   1.07463947e-02,
         4.04403558e-02,   8.26039753e-03,   1.98522535e-01,
                    nan,   4.01079252e-02,   3.29562706e-02,
         2.62750509e-02,   2.15995411e-01,   2.39457293e-01,
                    nan,   1.61113336e-02,   5.35657477e-02,
         1.11190171e-01,   1.11338145e-01,   6.21744347e-02,
                    nan,   1.81105575e-02,   1.84985307e-01,
         1.33219838e-01,   1.08569812e-01,   2.01393872e-01,
                    nan,   0.00000000e+00,   4.16653333e+00,
         5.65685425e+00,   9.86711711e+00,   5.84465568e+00,
         4.16653333e+00,   0.00000000e+00,   6.85273668e+00,
         5.01996016e+00,   3.61109402e+00,   5.65685425e+00,
         6.85273668e+00,   0.00000000e+00,   5.49181209e+00,
         5.09901951e+00,   9.86711711e+00,   5.01996016e+00,
         5.49181209e+00,   0.00000000e+00,   5.08330601e+00,
         5.84465568e+00,   3.61109402e+00,   5.09901951e+00,
         5.08330601e+00,   0.00000000e+00,   8.48761187e-02])]}
